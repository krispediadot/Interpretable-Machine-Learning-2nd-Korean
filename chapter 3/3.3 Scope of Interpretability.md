##### 3.3 해석가능성의 범위
---

알고리즘은 예측을 하는 모델을 학습시킨다. 각 단계는 투명성 또는 해석가능성으로 평가될 수 있다.

3.3.1 알고리즘 투명성

어떻게 알고리즘이 모델을 만드는가?

알고리즘 투명성은 알고리즘이 데이터로부터 모델을 어떻게 학습시키는지 그리고 어떤 연결관계를 학습할 수 있는지에 대한 것이다. 만약 이미지를 분류하기 위해 convolutional neural network를 사용한다면, 그 알고리즘이 엣지 추출과 낮은 레벨에서의 필터를 학습한다고 설명할 수 있다. 이것은 알고리즘이 어떻게 동작하는지에 대한 이해이고, 최종적으로 학습되는 특정 모델에 관한 것도 아니고, 어떻게 예측 결과가 생성되는지에 대한 이야기도 아니다. 알고리즘 투명성은 알고리즘에 대한 지식만을 요구하고 데이터와 학습된 모델에 대한 것은 요구하지 않는다. 이 책은 알고리즘의 투명성보다는 모델의 해석가능성에 대해 중점적으로 다룬다. 선형 모델의 최소자승법과 같은 알고리즘은 충분이 학습되었고 이해되었다. 고도의 투명성에 의해 특징화되었다. 딥러닝은 아질 잘 이해되지 않았고 내부 동작들은 아직 연구 중에 있다. 딥러닝은 덜 투명한 방법으로 간주된다. 


3.3.2 global하고 전반적인 모델 해석가능성

어떻게 학습된 모델이 예측을 하는가?

만약 전체 모델을 한번에 이해할 수 있다면 그 모델을 설명할 수 있을 것이다(Lipton 2016). 모델 결과를 설명하기 위해 학습된 모델, 알고리즘에 대한 지식 그리고 데이터에 대한 지식이 필요하다. 이러한 해석가능성의 레벨은 모델이 어떻게 예측을 하는지 모델의 특성과 wight, 파라미터, 구조 등 각 학습 요소들에 대한 전반적인 안목에 기반해서 이해하는 것이다. 어떤 특성이 중요하고 각 특성 사이 어떤 관계가 있는지? global 모델 해석가능성은 타겟의 결과를 각 특성에 기반해 이해하는 것을 돕는다. global 모델 해석가능성은 실제에서는 매우 달성하기 어렵다. 모델의 파라미터 또는 weight는 평균적인 인간의 단기 메모리 영역을 벗어난다. 5개의 특성을 가진 선형 모델을 상상할 수 없을 것이라 주장하는데, 그 이유는 5차원 공간으로 구성된 hyperplane을 상상속에 그리는 것과 같기 때문이다. 인간은 3차원 이상의 공간을 상상할 수 없다. 보통, 모델을 이해하기위해 선형 모델의 weight와 같이 일부만을 가지고 이해한다. 

3.3.3 모듈 레벨에서의 global 모델 해석가능성

어떨게 모델의 각 파트들이 예측에 영항을 주는가?

수백개의 특성을 가진 Naive Bayes 모델은 머릿속에서 다루기에는 너무 크다. 모든 weight를 관리하기 위해 기억한다 하더라도 빠르게 새로운 데이터 포인트에 대해 예측을 하는것은 불가능하다. 게다가, 각 특성들의 중요도와 각 특성이 예측에 평균적으로 얼마나 영향을 주는지를 추측하기 위해 머릿속에 모든 특성들에 대한 연결 분포가 필요하다. 이건 불가능한 일이다. 그러나 하나의 weight를 이해하는건 쉬운 일이다. 비록 global한 모델 해석가능성은 이룰 수 없지만, 몇몇 모델은 모듈 레벨에서 이해할 수 있다. 모든 모델이 파라미터 레벨에서 해석할 수 있는 것은 아니다. 선형 모델에서는 weight가 해석할 수 있는 부분이고, 트리 모델에서는 split(선택된 특성과 cut-off point) 그리고 리프 노드의 예측이 해석할 수 있는 부분이다. 선형모델을 예를 들면, 모듈 레벨에서 완벽하게 해석될 수 있을 것 처럼 보이지만, 하나의 weight를 해석하는 것은 다른 weight와 연결되어있다. weight 하나의 해석은 다른 입력 특성들은 그대로 인 경우에만 가능하고 이는 실제 어플리케이션에서는 일어날 수 없는 일이다. 집 값을 예측하는 선형 모델은 집의 크기와 방의 개수가 고려되고 방과 관련된 특성에서는 음의 weight를 가질 수 있다. 집 크기 특성이 이미 매우 높게 연관되어 있기 때문에 이와 같은 상황이 발생할 수 있다. 사람들이 큰 방을 선호하는 마켓에서는, 집 전체 크기가 같다면 방을 적게 가진 집이 방을 많이 가진 집보다 더 가치있을 수 있다. weight는 모델의 다른 특성들과의 상호 관계에 의해서만 이해 된다. 그러나 선형 모델의 weight는 deep neural network의 weight보다 잘 이해될 수 있다는 점은 변함 없다. 

3.3.4 하나의 예측에 대한 local한 해석가능성

왜 모델이 특정 입력에 대해 특정 예측을 하는 것인가?

하나의 입력에 국한해 이 모델이 어떤 예측을 하는지 그리고 왜 그러한 예측을 하는지 살펴볼 수 있다. 하나의 예측을 살펴보면, 복잡한 모델의 행동이 좀 더 간단해 보일 것이다. 지역적으로, 예측은 선형적으로 또는 단조롭게만 의존하고 있을 수도 있다. 예를 들어, 집 값은 단순히 집의 크기에만 의존하는 것처럼 안보일 수도 있다. 그러나, 만약 집의 100 제곱미터만 살펴보면 모델의 결과는 단순히 집의 크기에만 영향을 받은 것일 가능성이 있다. 집의 크기를 10 제곱미터씩 변경하는 시뮬레이션을 통해 이러한 사실을 확인해볼 수 있다. 그러므로 지역적 설명은 global 설명보다 더 정확할 수 있다. 이 책에서는 model-agnostic 방법 파트에서 각각의 예측이 더 해석가능한 방법들을 소개할 것이다. 

3.3.5 한 그룹의 예측에 대한 local한 해석가능성

왜 모델이 특정 그룹에 대해 특정 예측을 하는 것인가?

다중 입력에 대한 모델의 예측은 global 모델 해석 방법 또는 각 입력에 대한 설명 두가지 방법 모두로 설명 될 수 있다. global 방법은 다중 입력을 완벽한 데이터 셋으로 간주하고 이 subset에 대해 global한 방법을 적용한다. 각 입력에 대한 설명 방법은 각 입력을 리스팅 하거나 합쳐서 사용한다. 

8. Lipton, Zachary C. “The mythos of model interpretability.” arXiv preprint arXiv:1606.03490,
(2016).↩︎
