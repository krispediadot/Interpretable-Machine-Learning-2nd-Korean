##### 3.1 해석가능성의 중요성
---

만약 머신러닝 모델이 잘 동작한다면, 그냥 머신러닝 모델을 믿고 왜 이런 결과를 냈는지 무시해도 되지 않을까? "실제 업무 상에서의 문제는 분류 정확도처럼 하나의 수치가 부정하게 정의되어있다는 점이다." (Doshi-Velez and Kim 2017)

해석가능성이 왜 중요한지에 대해 조금 더 살펴보자. 예측 모델에서는 트레이드오프를 신경써야한다: 소비자 이탈율 또는 약이 환자에게 얼마나 효과적인지 등 무엇이 에측되었는지를 알고싶은지? 아니면 왜 이런 결과가 나왔는지를 알고 싶은지?(Or do you want to know why the prediction was made and possibly pay for the interpretability with a drop in predictive performance?) 몇몇 상황에서는 왜 이런 결정이 되었는지 신경쓰지 않고 테스트 데이터의 성능이 잘 나왔다는 것만 확인하는 경우가 있다. 다른 몇몇 상황에서는 데이터와 왜 모델이 실패할 것인지에 대해 이해하는 것이 직면한 문제를 이해하는데 도움이 된다. 몇몇 모델들은 이미 검증되거나 리스크가 적은 환경에서 사용되어 실패하더라도 심각한 결과를 마주하지 않아도 되어서 설명이 필요 없을 수 있다. 해석가능성은 문제 상황의 불완전성으로부터 필요성이 대두되고 이는 특정 문제 또는 주어진 문제는 예측을 하는 것만으로는 부족하다는 것을 의미한다. 올바른 예측은 기존 문제의 일부만 해결할 수 있으므로 왜 이런 예측이 나왔는지에 대한 설명이 필요하다. 뒤에 나오는 여러 이유들은 해석가능성과 설명의 필요성에 대해 말해준다.(Doshi-Velez and Kim 2017 and Miller 2017)

인간의 호기심과 학습: 인간은 예상하지 못한 일이 발생했을 때 주변 환경에 대한 정보가 업데이트 되는 정신적 모델을 가지고 있다. 이러한 업데이트는 예상치 못한 이벤트에 대한 설명을 찾는 과정에서 발생한다. 예를들어, 한 사람이 예상치 못하게 아프고 왜 아픈지 묻는다. 그는 붉은 베리를 먹을 때 마다 아프다는 것을 학습한다. 그는 붉은 베리는 아픔을 유발하고 그러므로 피해야한다는 것을 정신적 모델에 업데이트한다. 불투명한 모델이 연구에 사용어서 모델이 설명 없이 예측 결과만 알려준다면 과학적 발견은 감춰진 채로 유지될 것이다. 왜 특정 결과를 예측했는지 또는 특정 행동을 기계가 하는지에 대해 배우고 호기심을 채우기 위해서는, 해석가능성과 설명은 중요하다. 당연히, 인간은 모든 일에 대해서 설명이 필요하지 않다. 대부분의 사람들은 어떻게 컴퓨터가 동작하는지 몰라도 괜찮다. 예상치 못한 이벤트는 궁금증을 유발한다. 예를들어, 왜 컴퓨터가 갑자기 꺼지는지?

학습과 밀접하게 된련된 인간의 욕망은 세상에서 새로운 의미를 찾는 것이다. 우리는 지식 구조의 요소들 사이 모순과 불연속성에서 조화를 이루기를 원한다. "이전엔 안그러던 개가 왜 값자기 물까?" 인간이 의문을 품는다. 개의 과거 행동과 새로운 행동의 모순 그리고 물림이라는 달갑지 않은 경험의 모순이 있다. 수의사의 설명이 개 주인의 모순을 중재한다. "개가 스트레스를 받아서 그래요." 기계의 결정이 인간의 삶에 영향을 크게 미치면 미칠수록 기계의 행동을 설명하는 것은 더욱 중요해진다. 만약 머신러닝 모델이 대출 신청자를 거절한다면, 대출 신청자에게는 예상치 못한 일일 것이다. 그들의 예상했던 결과와 실제 결과에 대한 불연속성은 설명만으로 중재가 될 것이다. 설명이 상황을 모두 설명할 순 없지만 해당 상황이 발생한 주요 원인은 설명해줘야한다. 다른 예시로는 물건 추천 알고리즘이 있다. 개인적으로 왜 특정 물건이 또는 특정 영화가 나에게 추천되는 것인지 항상 생각한다. 종종 이유는 명확하다: 최근에 세탁기를 샀기 때문에 며칠 뒤 세탁기 광고를 받게 될 것이란 것을 알고 있다. 만약 겨울 모자가 쇼핑 카트에 들어있다면 장갑을 제안하는 것은 말이 된다. 특정 영화를 추천해주는 이유는 다른 영화를 좋아했던 사람들은 추천된 영화를 좋아하기 때문이다. 점점 인터넷 회사들은 그들의 추천에 대한 설명을 추가하는 추세이다. 가장 좋은 예시는 자주 구매하는 제품의 조합으로 제품을 추천해주는 시스템이다.

많은 과학 분야는 질적 방법에서 양적 방법으로 그리고 머신러닝 방법으로 변화하는 추세이다. 과학의 목적은 지식을 얻는것인데 많은 문제들이 대규모 데이터와 블랙박스 머신러닝 모델으로 풀리고있다는 점이다. 데이터가 아닌 모델 자체가 지식의 근원이 되고 있다. 해석가능성은 모델에서 추가적인 지식을 추출할 수 있도록 도와준다.

머신러닝 모델은 안전한 측정과 테스팅이 필요한 현실세계의 문제를 다룬다. 자율주행 자동차가 딥러닝 시스템을 기반으로 자전거타는 사람을 자동으로 인식하는 것을 상상해보라. 자전거를 타고 가는 사람을 넘어서 가는 것은 위험하므로 오류에서 자유롭고 100% 신뢰하는 시스템을 원할 것이다. 두개의 바퀴가 자전거 타는 사람을 인식하는 주요 원인이다 처럼 모델의 결정에 대한 설명은 결정의 원인이 된 가장 중요한 특징을 알려줄 것이고 이는 가방으로 일부 가려진 자전거 바퀴 등 edge case를 생각하는데 도움을 줄 것이다.

기본적으로, 머신러닝 모델은 학습 데이터의 편향을 배운다. 이는 머신러닝 모델이 학습 데이터셋에 충분히 표현되지 않은 그룹을 차별하는 인종차별주의자로 만들 수도 있다. 해석가능성은 머신러닝 모델의 편향을 디버깅하는 도구로 사용할 수 있다. 자동으로 신용 대출 신청자를 승인 또는 거절하는 머신러닝 모델이 그동안 권리를 박탈당해온 소수자를 차별할 수도 있다. 모델의 주된 목적은 최종 빌린 돈을 갚을 사람들에게 대출을 해 주는 것이다. 이 케이스에서 불완전한 문제의 수식은 대출의 기본을 낮추는것 뿐만 아니라 특정 인구를 차별하지 않는 것도 포함되어야한다. 이는 문제의 수식에 추가적인 제약조건이고 머신러닝 모델이 최적화하는 손실함수로 커버될 수 없는 영역이다.

